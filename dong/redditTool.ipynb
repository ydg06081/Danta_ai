{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0bacecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client ID: P3LdN...\n",
      "--- r/stocksì—ì„œ [2024-10-01 ~ 2025-10-01] ê¸°ê°„ì˜ [ì¸ê¸° ê¸€] ìˆ˜ì§‘ ì‹œì‘ ---\n",
      "[ì „ëµ 1] 'ì§€ë‚œ 1ë…„' ì¸ê¸° ê¸€(Top 1000)ì„ í™•ì¸í•©ë‹ˆë‹¤...\n",
      "[ì „ëµ 2] 'ì—­ëŒ€' ì¸ê¸° ê¸€(Top 1000)ì„ í™•ì¸í•©ë‹ˆë‹¤...\n",
      "\n",
      "--- ì´ 232ê°œì˜ ê³ ìœ í•œ ì¸ê¸° ê¸€ ìˆ˜ì§‘ ì™„ë£Œ ---\n",
      "ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤...\n",
      "\n",
      "âœ… Reddit í¬ë¡¤ë§ ì™„ë£Œ. ì´ 232ê°œ ìˆ˜ì§‘.\n",
      "  [ê°€ì¥ ì˜¤ë˜ëœ ê¸€] 2024-11-12: Elon Muskâ€™s Trump bet has paid off so well that Te...\n",
      "  [ê°€ì¥ ìµœì‹  ê¸€]   2025-09-29: How will Microsoft stock react to this news on Mon...\n",
      "\n",
      "ğŸ’¾ stocks_2024-10-01_to_2025-10-01.json íŒŒì¼ë¡œ ì €ì¥ ì¤‘...\n",
      "âœ… stocks_2024-10-01_to_2025-10-01.json íŒŒì¼ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint as pp\n",
    "import praw\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---\n",
    "# .env íŒŒì¼ì—ì„œ ìê²© ì¦ëª…ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    env_path = os.path.join('.env')\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "    client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "    client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "\n",
    "    if not client_id or not client_secret:\n",
    "        print(\"REDDIT_CLIENT_ID ë˜ëŠ” REDDIT_CLIENT_SECRETì´ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "    \n",
    "    print(f\"Client ID: {client_id[:5]}...\") # Client ID ë¡œë“œ í™•ì¸\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\".env íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. PRAW ì¸ì¦ (ë‹¨ìˆœí™”) ---\n",
    "# PRAWëŠ” IDì™€ Secretë§Œìœ¼ë¡œ ì¸ì¦ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "# requestsë¥¼ ì‚¬ìš©í•œ ìˆ˜ë™ í† í° ë°œê¸‰ì€ ì „í˜€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "try:\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=\"ydg06081-top-search/1.0\" # User-AgentëŠ” í•„ìˆ˜\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"PRAW ì¸ì¦ ì‹¤íŒ¨: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. ë‚ ì§œ ì„¤ì • (í•„í„°ë§ìš©) ---\n",
    "# ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì‹¤ì œ ê¸°ê°„\n",
    "start_date_str = \"2024-10-01\"\n",
    "end_date_str = \"2025-10-01\"\n",
    "start_ts = int(datetime.strptime(start_date_str, \"%Y-%m-%d\").timestamp())\n",
    "end_ts = int(datetime.strptime(end_date_str, \"%Y-%m-%d\").timestamp())\n",
    "\n",
    "# --- 4. ë°ì´í„° ìˆ˜ì§‘ (.top() ì „ëµ ì‚¬ìš©) ---\n",
    "\n",
    "#==================================ì„œë¸Œë ˆë”§===========================================\n",
    "subreddit_name = \"stocks\" # ì‚¬ìš©ìë‹˜ì´ ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹  subreddit\n",
    "#=====================================================================================\n",
    "\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "print(f\"--- r/{subreddit_name}ì—ì„œ [{start_date_str} ~ {end_date_str}] ê¸°ê°„ì˜ [ì¸ê¸° ê¸€] ìˆ˜ì§‘ ì‹œì‘ ---\")\n",
    "\n",
    "collected_posts_dict = {} # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (post.id -> post ê°ì²´)\n",
    "\n",
    "# [ì „ëµ 1: \"ì§€ë‚œ 1ë…„\" (Year) ì¸ê¸° ê¸€ ìˆ˜ì§‘]\n",
    "print(\"[ì „ëµ 1] 'ì§€ë‚œ 1ë…„' ì¸ê¸° ê¸€(Top 1000)ì„ í™•ì¸í•©ë‹ˆë‹¤...\")\n",
    "try:\n",
    "    # time_filter=\"year\"ëŠ” ì˜¤ëŠ˜(2025-11-18) ê¸°ì¤€ ì§€ë‚œ 1ë…„ì¹˜ë¥¼ ê°€ì ¸ì˜´\n",
    "    for post in subreddit.top(time_filter=\"year\", limit=1000):\n",
    "        post_ts = post.created_utc\n",
    "        # ê°€ì ¸ì˜¨ ì¸ê¸° ê¸€ì„ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë‚ ì§œ ë²”ìœ„(2024-10 ~ 2025-10)ë¡œ ë‹¤ì‹œ í•„í„°ë§\n",
    "        if start_ts <= post_ts <= end_ts:\n",
    "            if post.id not in collected_posts_dict:\n",
    "                collected_posts_dict[post.id] = post\n",
    "except Exception as e:\n",
    "    print(f\"ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Year): {e}\")\n",
    "\n",
    "# [ì „ëµ 2: \"ì—­ëŒ€\" (All-Time) ì¸ê¸° ê¸€ ìˆ˜ì§‘]\n",
    "print(\"[ì „ëµ 2] 'ì—­ëŒ€' ì¸ê¸° ê¸€(Top 1000)ì„ í™•ì¸í•©ë‹ˆë‹¤...\")\n",
    "try:\n",
    "    # time_filter=\"all\"ëŠ” ì—­ëŒ€ ì¸ê¸°ê¸€ 1000ê°œë¥¼ ê°€ì ¸ì˜´\n",
    "    for post in subreddit.top(time_filter=\"all\", limit=1000):\n",
    "        post_ts = post.created_utc\n",
    "        # ê°€ì ¸ì˜¨ ì¸ê¸° ê¸€ì„ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë‚ ì§œ ë²”ìœ„(2024-10 ~ 2025-10)ë¡œ ë‹¤ì‹œ í•„í„°ë§\n",
    "        if start_ts <= post_ts <= end_ts:\n",
    "            if post.id not in collected_posts_dict:\n",
    "                collected_posts_dict[post.id] = post\n",
    "except Exception as e:\n",
    "    print(f\"ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (All): {e}\")\n",
    "\n",
    "# --- 5. ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë³€í™˜ (ì‚¬ìš©ìë‹˜ í˜•ì‹ ìœ ì§€) ---\n",
    "posts = []\n",
    "print(f\"\\n--- ì´ {len(collected_posts_dict)}ê°œì˜ ê³ ìœ í•œ ì¸ê¸° ê¸€ ìˆ˜ì§‘ ì™„ë£Œ ---\")\n",
    "print(\"ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# ë”•ì…”ë„ˆë¦¬ì— ëª¨ì€ post ê°ì²´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "for post in collected_posts_dict.values():\n",
    "    post_time = datetime.fromtimestamp(post.created_utc)\n",
    "    posts.append({\n",
    "        \"title\": post.title,\n",
    "        \"url\": post.url,\n",
    "        \"created\": post_time,\n",
    "        \"score\": post.score,\n",
    "        \"num_comments\": post.num_comments,\n",
    "        \"author\": str(post.author),\n",
    "        \"selftext\": post.selftext\n",
    "    })\n",
    "\n",
    "# ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ìˆœ)\n",
    "posts.sort(key=lambda x: x['created'])\n",
    "\n",
    "# --- 6. ê²°ê³¼ ìš”ì•½ ì¶œë ¥ ---\n",
    "if posts:\n",
    "    print(f\"\\nâœ… Reddit í¬ë¡¤ë§ ì™„ë£Œ. ì´ {len(posts)}ê°œ ìˆ˜ì§‘.\")\n",
    "    print(f\"  [ê°€ì¥ ì˜¤ë˜ëœ ê¸€] {posts[0]['created'].strftime('%Y-%m-%d')}: {posts[0]['title'][:50]}...\")\n",
    "    print(f\"  [ê°€ì¥ ìµœì‹  ê¸€]   {posts[-1]['created'].strftime('%Y-%m-%d')}: {posts[-1]['title'][:50]}...\")\n",
    "else:\n",
    "    print(\"âœ… Reddit í¬ë¡¤ë§ ì™„ë£Œ. í•´ë‹¹ ê¸°ê°„ì— ìˆ˜ì§‘ëœ ì¸ê¸° ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# --- 7. JSON íŒŒì¼ë¡œ ì €ì¥ ---\n",
    "if posts:\n",
    "    output_filename = f\"{subreddit_name}_{start_date_str}_to_{end_date_str}.json\"\n",
    "    print(f\"\\nğŸ’¾ {output_filename} íŒŒì¼ë¡œ ì €ì¥ ì¤‘...\")\n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            # datetime ê°ì²´ëŠ” JSONìœ¼ë¡œ ë°”ë¡œ ì €ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ\n",
    "            # default=strì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "            json.dump(posts, f, ensure_ascii=False, indent=4, default=str)\n",
    "        print(f\"âœ… {output_filename} íŒŒì¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
