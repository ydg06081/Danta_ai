import os
from pathlib import Path

import pandas as pd
from dotenv import load_dotenv
from google import genai
from google.genai import types
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm.auto import tqdm
import time

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
RESULTS_DIR = BASE_DIR / "pro_data" / "results"
INPUT_FILE = RESULTS_DIR / "us_economic_data.csv"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
env_path = BASE_DIR / ".env"
load_dotenv(dotenv_path=env_path)

# ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
BATCH_SIZE = 5
BATCH_DELAY = 3


def call_gemini(input_text: str) -> str:
    """Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê±°ì‹œê²½ì œ ë¶„ì„ì„ ë°›ì•„ì˜µë‹ˆë‹¤."""
    client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
    model = "gemini-2.0-flash"
    prompt = (
        f"""
        ì—­í• : ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ë…¸ë ¨í•œ 'ë§¤í¬ë¡œ íˆ¬ì ì „ëµê°€'ì…ë‹ˆë‹¤.

ëª©í‘œ: ì•„ë˜ ì œê³µëœ [ì¼ì, ë¹„íŠ¸ì½”ì¸ ê°€ê²©, ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬, ë¯¸êµ­ GDP] ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì£¼ì‹ ì‹œì¥ íˆ¬ì ì „ëµì„ ìœ„í•œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ ì£¼ì„¸ìš”.

ë°ì´í„° ì„¤ëª…:
- ë¹„íŠ¸ì½”ì¸ ê°€ê²©: ì‹œì¥ ë‚´ 'ìœ ë™ì„±'ê³¼ 'ìœ„í—˜ ìì‚° ì„ í˜¸ ì‹¬ë¦¬(Risk Appetite)'ì˜ ì„ í–‰ ì§€í‘œë¡œ í•´ì„í•©ë‹ˆë‹¤.
- ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬: ì£¼ì‹ ë°¸ë¥˜ì—ì´ì…˜(PER) ì••ë°• ìš”ì¸ì´ì ìë³¸ ì¡°ë‹¬ ë¹„ìš©ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤.
- ë¯¸êµ­ GDP: ê²½ê¸° ì¹¨ì²´(Recession) ì—¬ë¶€ì™€ ê¸°ì—… ì´ìµì˜ ê¸°ì´ˆ ì²´ë ¥ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤.

ìš”ì²­ ì‚¬í•­:
1. [ìƒê´€ê´€ê³„ ë¶„ì„] ê¸ˆë¦¬ ë³€í™”ì™€ GDP ì¶”ì„¸ê°€ ë¹„íŠ¸ì½”ì¸(ìœ„í—˜ ìì‚° ì‹¬ë¦¬)ì— ë¯¸ì¹œ ì˜í–¥ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”. (ì˜ˆ: ê¸ˆë¦¬ ì¸ìƒê¸°ì— ë¹„íŠ¸ì½”ì¸ ê°€ê²© ë°©ì–´ ì—¬ë¶€ ë“±)
2. [êµ­ë©´ íŒë‹¨] ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬(ë˜ëŠ” ê°€ì¥ ìµœê·¼ ë°ì´í„° ì‹œì ) ê²½ì œê°€ ë‹¤ìŒ 4ê°€ì§€ êµ­ë©´ ì¤‘ ì–´ë””ì— í•´ë‹¹í•˜ëŠ”ì§€ ì •ì˜í•´ ì£¼ì„¸ìš”.
   - ê³¨ë””ë½ìŠ¤ (ì„±ì¥â†‘, ê¸ˆë¦¬ ì•ˆì •)
   - ìŠ¤íƒœê·¸í”Œë ˆì´ì…˜ (ì„±ì¥â†“, ë¬¼ê°€/ê¸ˆë¦¬â†‘)
   - ê²½ê¸° ì¹¨ì²´ (ì„±ì¥â†“, ê¸ˆë¦¬â†“)
   - ê¸´ì¶• ê³¼ì—´ (ì„±ì¥â†‘, ê¸ˆë¦¬â†‘)
3. [ì£¼ì‹ íˆ¬ì ì „ëµ] ìœ„ êµ­ë©´ íŒë‹¨ì— ë”°ë¼ ì£¼ì‹ í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµì„ ì œì•ˆí•´ ì£¼ì„¸ìš”.
   - ë¹„ì¤‘ í™•ëŒ€/ì¶•ì†Œ ì—¬ë¶€ (ê³µê²©ì  íˆ¬ì vs í˜„ê¸ˆ í™•ë³´)
   - ìœ ë¦¬í•œ ì„¹í„° ì¶”ì²œ (ì˜ˆ: ê¸ˆë¦¬ í•˜ë½+ì„±ì¥ ë‘”í™” ì‹œ â†’ í•„ìˆ˜ì†Œë¹„ì¬/ë°°ë‹¹ì£¼, ê¸ˆë¦¬ ì•ˆì •+ë¹„íŠ¸ì½”ì¸ ìƒìŠ¹ ì‹œ â†’ ê¸°ìˆ ì£¼/ì„±ì¥ì£¼)

Input_text:
{input_text}
        """
    )

    contents = [
        types.Content(
            role="user",
            parts=[types.Part.from_text(text=prompt)],
        ),
    ]

    response = client.models.generate_content(
        model=model,
        contents=contents,
    )
    return response.text


def process_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """DataFrameì„ ì¼ìë³„ë¡œ Geminiì— ì „ë‹¬í•˜ê³  ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    df = df.sort_values(by="ì¼ì").reset_index(drop=True)

    print(f"[ê±°ì‹œê²½ì œ] ì „ì²´ ë°ì´í„°: {len(df)}ì¼")
    print(f"[ê±°ì‹œê²½ì œ] ê¸°ê°„: {df['ì¼ì'].min()} ~ {df['ì¼ì'].max()}")
    print(f"[ê±°ì‹œê²½ì œ] ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°:")
    print(df.head())

    tasks = []
    for _, row in df.iterrows():
        date = row["ì¼ì"]
        data_text = (
            f"ì¼ì: {row['ì¼ì']}\n"
            f"ë¹„íŠ¸ì½”ì¸ ê°€ê²©: ${row['ë¹„íŠ¸ì½”ì¸ê°€ê²©(USD)']:,.2f}\n"
            f"ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬: {row['ë¯¸êµ­ê¸°ì¤€ê¸ˆë¦¬(%)']}%\n"
            f"ë¯¸êµ­ GDP: {row['ë¯¸êµ­GDP(ì‹­ì–µë‹¬ëŸ¬)']:,.3f} ì‹­ì–µ ë‹¬ëŸ¬\n"
        )
        tasks.append((date, data_text))

    print(f"\n[ê±°ì‹œê²½ì œ] ì²˜ë¦¬í•  ì¼ì ìˆ˜: {len(tasks)}ê°œ\n")

    results = []
    success_count = 0
    error_count = 0
    total_batches = (len(tasks) + BATCH_SIZE - 1) // BATCH_SIZE

    with tqdm(total=len(tasks), desc="ê±°ì‹œê²½ì œ ë¶„ì„ ì§„í–‰", unit="ì¼ì") as pbar:
        for batch_idx in range(0, len(tasks), BATCH_SIZE):
            batch = tasks[batch_idx:batch_idx + BATCH_SIZE]
            current_batch = batch_idx // BATCH_SIZE + 1
            pbar.set_postfix({"ë°°ì¹˜": f"{current_batch}/{total_batches}", "ì„±ê³µ": success_count, "ì˜¤ë¥˜": error_count})

            with ThreadPoolExecutor(max_workers=BATCH_SIZE) as executor:
                future_to_task = {
                    executor.submit(call_gemini, data_text): (date, data_text)
                    for date, data_text in batch
                }

                for future in as_completed(future_to_task):
                    date, data_text = future_to_task[future]
                    try:
                        gemini_response = future.result()
                        results.append(
                            {
                                "ì¼ì": date,
                                "ì›ë³¸ë‚´ìš©": data_text,
                                "ë‹µë³€": gemini_response,
                            }
                        )
                        success_count += 1
                    except Exception as e:
                        error_count += 1
                        results.append(
                            {
                                "ì¼ì": date,
                                "ì›ë³¸ë‚´ìš©": data_text,
                                "ë‹µë³€": f"ì˜¤ë¥˜: {str(e)}",
                            }
                        )
                    pbar.set_postfix({"ë°°ì¹˜": f"{current_batch}/{total_batches}", "ì„±ê³µ": success_count, "ì˜¤ë¥˜": error_count})
                    pbar.update(1)

            if batch_idx + BATCH_SIZE < len(tasks):
                time.sleep(BATCH_DELAY)

    print(f"\n[ê±°ì‹œê²½ì œ] âœ… ì²˜ë¦¬ ì™„ë£Œ! ì„±ê³µ {success_count}ê°œ / ì˜¤ë¥˜ {error_count}ê°œ\n")
    return pd.DataFrame(results)


def main():
    if not INPUT_FILE.exists():
        raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_FILE}")

    # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š ê±°ì‹œê²½ì œ ë°ì´í„° Gemini ë¶„ì„")
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {INPUT_FILE}")
    print(f"{'='*60}\n")

    df = pd.read_csv(INPUT_FILE)
    result_df = process_dataframe(df)
    
    # ì¼ììˆœ ì •ë ¬
    result_df = result_df.sort_values(by="ì¼ì").reset_index(drop=True)
    
    output_path = RESULTS_DIR / "ê±°ì‹œê²½ì œ_gemini_results.csv"
    result_df.to_csv(output_path, index=False, encoding="utf-8-sig")
    
    print(f"{'='*60}")
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ğŸ“Š ì´ {len(result_df)}ì¼ ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()
